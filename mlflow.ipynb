{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import mlflow # mlflow 사용을 위해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784,100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100,100)\n",
    "        self.fc3 = nn.Linear(100,10)\n",
    "    def forward(self, x):\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.relu(x1)\n",
    "        x3 = self.fc2(x2)\n",
    "        x4 = self.relu(x3)\n",
    "        x5 = self.fc3(x4)\n",
    "\n",
    "        return x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 정의  \n",
    "## MNIST Dataset을 사용하여 학습,검증을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_root = 'MNIST_data/'\n",
    "\n",
    "train_dataset = datasets.MNIST(root=download_root,\n",
    "                         train=True,\n",
    "                         transform = transforms.ToTensor(),\n",
    "                         download=True)\n",
    "                         \n",
    "test_dataset = datasets.MNIST(root=download_root,\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch_size, Train, Test Dataloader 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습률, Optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.zero_grad()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.03\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed 고정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow를 활용하여 학습진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Model(Epoch: 1, Accuracy: 97.28)\n",
      "epoch : 1 | loss : 0.075140\n",
      "Accuracy : 97.28\n",
      "------\n",
      "epoch : 2 | loss : 0.071241\n",
      "Accuracy : 97.20\n",
      "------\n",
      "epoch : 3 | loss : 0.067813\n",
      "Accuracy : 97.22\n",
      "------\n",
      "Save Model(Epoch: 4, Accuracy: 97.4)\n",
      "epoch : 4 | loss : 0.064229\n",
      "Accuracy : 97.40\n",
      "------\n",
      "Save Model(Epoch: 5, Accuracy: 97.54)\n",
      "epoch : 5 | loss : 0.061828\n",
      "Accuracy : 97.54\n",
      "------\n",
      "epoch : 6 | loss : 0.059050\n",
      "Accuracy : 97.43\n",
      "------\n",
      "epoch : 7 | loss : 0.056180\n",
      "Accuracy : 97.43\n",
      "------\n",
      "epoch : 8 | loss : 0.053763\n",
      "Accuracy : 97.46\n",
      "------\n",
      "Save Model(Epoch: 9, Accuracy: 97.59)\n",
      "epoch : 9 | loss : 0.051223\n",
      "Accuracy : 97.59\n",
      "------\n",
      "Save Model(Epoch: 10, Accuracy: 97.72)\n",
      "epoch : 10 | loss : 0.049236\n",
      "Accuracy : 97.72\n",
      "------\n",
      "epoch : 11 | loss : 0.047035\n",
      "Accuracy : 97.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/31 15:48:14 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under /home/khkim/aip/AIP/artifacts/1/04a788d93e754ee68e3d840dd7aaf492/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "epoch : 12 | loss : 0.045077\n",
      "Accuracy : 97.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/31 15:48:24 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under /home/khkim/aip/AIP/artifacts/1/04a788d93e754ee68e3d840dd7aaf492/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "epoch : 13 | loss : 0.043192\n",
      "Accuracy : 97.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/31 15:48:34 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under /home/khkim/aip/AIP/artifacts/1/04a788d93e754ee68e3d840dd7aaf492/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "epoch : 14 | loss : 0.041451\n",
      "Accuracy : 97.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/31 15:48:44 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under /home/khkim/aip/AIP/artifacts/1/04a788d93e754ee68e3d840dd7aaf492/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Save Model(Epoch: 15, Accuracy: 97.75)\n",
      "epoch : 15 | loss : 0.039996\n",
      "Accuracy : 97.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/31 15:48:55 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under /home/khkim/aip/AIP/artifacts/1/04a788d93e754ee68e3d840dd7aaf492/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Save Model(Epoch: 16, Accuracy: 97.8)\n",
      "epoch : 16 | loss : 0.037991\n",
      "Accuracy : 97.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/31 15:49:05 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under /home/khkim/aip/AIP/artifacts/1/04a788d93e754ee68e3d840dd7aaf492/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "epoch : 17 | loss : 0.036782\n",
      "Accuracy : 97.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/31 15:49:16 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under /home/khkim/aip/AIP/artifacts/1/04a788d93e754ee68e3d840dd7aaf492/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "epoch : 18 | loss : 0.035090\n",
      "Accuracy : 97.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/31 15:49:26 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under /home/khkim/aip/AIP/artifacts/1/04a788d93e754ee68e3d840dd7aaf492/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "epoch : 19 | loss : 0.033564\n",
      "Accuracy : 97.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/31 15:49:37 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under /home/khkim/aip/AIP/artifacts/1/04a788d93e754ee68e3d840dd7aaf492/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Save Model(Epoch: 20, Accuracy: 97.81)\n",
      "epoch : 20 | loss : 0.032471\n",
      "Accuracy : 97.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/31 15:49:47 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under /home/khkim/aip/AIP/artifacts/1/04a788d93e754ee68e3d840dd7aaf492/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'chaos_AIP' # 실험명, 실험관리를 용이하게 해줍니다. \n",
    "\n",
    "\n",
    "if not mlflow.get_experiment_by_name(experiment_name): \n",
    "  mlflow.create_experiment(name=experiment_name)\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000') # 로컬 서버에 실행을 기록하기 위해 함수 호출\n",
    "#mlflow.set_tag(\"mlflow.runName\",\"practice\")\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "total_batch = len(train_loader)\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "best_accuracy = 0\n",
    "with mlflow.start_run(experiment_id=experiment.experiment_id,run_name=\"boom\"):\n",
    "  for epoch in range(epochs):\n",
    "      cost=0\n",
    "      model.train()\n",
    "      train_accuracy = 0\n",
    "      train_loss = 0\n",
    "      for images, labels in train_loader:\n",
    "          images = images.reshape(100,784)\n",
    "          \n",
    "          optimizer.zero_grad() # 변화도 매개변수 0\n",
    "          \n",
    "          #forward\n",
    "          #pred = model.forward(images)\n",
    "          #loss = loss_function(pred, labels)\n",
    "          pred = model(images)\n",
    "          loss = loss_function(pred,labels)\n",
    "          prediction = torch.argmax(pred,1)\n",
    "          correct = (prediction == labels)\n",
    "          train_accuracy += correct.sum().item() / 60000\n",
    "          train_loss += loss.item() / 600\n",
    "          \n",
    "          #backward\n",
    "          loss.backward()\n",
    "          \n",
    "          #Update\n",
    "          optimizer.step()\n",
    "          \n",
    "          cost += loss\n",
    "      \n",
    "      with torch.no_grad(): #미분하지 않겠다는 것\n",
    "          total = 0\n",
    "          correct=0\n",
    "          for images, labels in test_loader:\n",
    "              images = images.reshape(100,784)\n",
    "\n",
    "              outputs = model(images)\n",
    "              _,predict = torch.max(outputs.data, 1)\n",
    "\n",
    "              total += labels.size(0)\n",
    "              correct += (predict==labels).sum() # 예측한 값과 일치한 값의 합\n",
    "\n",
    "      avg_cost = cost / total_batch\n",
    "      accuracy = 100*correct/total\n",
    "      \n",
    "      val_loss_list.append(avg_cost.detach().numpy())\n",
    "      val_acc_list.append(accuracy)\n",
    "\n",
    "      if accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(),'model.pt')\n",
    "        best_accuracy = accuracy\n",
    "        print(f\"Save Model(Epoch: {epoch+1}, Accuracy: {best_accuracy:.5})\")\n",
    "      \n",
    "      print(\"epoch : {} | loss : {:.6f}\" .format(epoch+1, avg_cost))\n",
    "      print(\"Accuracy : {:.2f}\".format(100*correct/total))\n",
    "      mlflow.log_param('learning-rate',learning_rate) # mlflow.log_param 을 사용하여 MLflow에 파라미터들을 기록할 수 있습니다.\n",
    "      mlflow.log_param('epoch',epochs)\n",
    "      mlflow.log_param('batch_size',batch_size)\n",
    "      mlflow.log_param('seed',seed)\n",
    "      mlflow.log_metric('train_accuracy',train_accuracy) # mlflow.log_metric을 사용하여 MLflow에 성능평가를 위한 metric을 기록할 수 있습니다.\n",
    "      mlflow.log_metric('train_loss',train_loss)\n",
    "      mlflow.log_metric('valid_accuracy',accuracy)\n",
    "      mlflow.log_metric('valid_loss',avg_cost)\n",
    "      mlflow.pytorch.log_model(model,'model') # pytorch.log_model 을 통해 모델을 저장할 수 있습니다.\n",
    "      print(\"------\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import bentoml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(tag=\"mnist_clf:pycdv6sy3wh6f2kn\", path=\"/home/khkim/bentoml/models/mnist_clf/pycdv6sy3wh6f2kn/\")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLFLOW_PATH = './model_mlflow'\n",
    "\n",
    "if not os.path.isdir(MLFLOW_PATH):\n",
    "  mlflow.pytorch.save_model(model, MLFLOW_PATH) # mlflow 모델 로컬 디렉토리에 저장\n",
    "\n",
    "bentoml.mlflow.import_model(\"mnist_clf\", model_uri='./model_mlflow') # mlflow로 저장한 모델을 bentoml format에 맞추어 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[0m\u001b[1mTag                       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mModule        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\n",
      " mnist_clf:pycdv6sy3wh6f2kn  bentoml.mlflow  355.39 KiB  2022-10-31 14:33:04 \n",
      " mnist_clf:klquv2syykh6f2kn  bentoml.mlflow  355.39 KiB  2022-10-31 11:18:35 \n",
      " mnist_clf:xkvy4zsyygh6f2kn  bentoml.mlflow  355.39 KiB  2022-10-31 11:14:20 \n",
      " mnist_clf:v65qkwsyych6f2kn  bentoml.mlflow  355.39 KiB  2022-10-31 11:06:52 \n"
     ]
    }
   ],
   "source": [
    "!bentoml models list mnist_clf # 현재 등록되어 있는 모델 리스트 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 테스트 데이터 가져오기\n",
    "with open('./test_input_arr.json', 'r') as f:\n",
    "  test_input_arr = np.array(json.load(f), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Runner.init_local' is for debugging and testing only.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -0.40538397,  -3.2523298 ,   3.0703802 ,   5.5641313 ,\n",
       "         -5.7938633 ,   0.3673871 , -12.363699  ,  11.423534  ,\n",
       "          1.1209784 ,   2.2345915 ],\n",
       "       [  2.5325568 ,   5.260461  ,  11.839561  ,   5.9065714 ,\n",
       "        -12.815116  ,   0.8554225 ,   3.3562913 ,  -7.457034  ,\n",
       "          1.7260301 , -12.618624  ],\n",
       "       [ -5.5542216 ,   7.381215  ,   0.96818936,  -0.879593  ,\n",
       "         -1.4426495 ,  -1.2838367 ,   0.17502701,   2.1546166 ,\n",
       "          1.496681  ,  -2.1817076 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 테스트\n",
    "runner = bentoml.mlflow.get(\"mnist_clf:latest\").to_runner()\n",
    "runner.init_local()\n",
    "runner.predict.run(test_input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.258671</td>\n",
       "      <td>-2.587523</td>\n",
       "      <td>3.675304</td>\n",
       "      <td>5.038008</td>\n",
       "      <td>-6.668222</td>\n",
       "      <td>-1.726515</td>\n",
       "      <td>-13.880798</td>\n",
       "      <td>11.955110</td>\n",
       "      <td>0.665868</td>\n",
       "      <td>2.337876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.636475</td>\n",
       "      <td>5.572082</td>\n",
       "      <td>13.566373</td>\n",
       "      <td>6.943092</td>\n",
       "      <td>-14.104278</td>\n",
       "      <td>3.698562</td>\n",
       "      <td>5.460308</td>\n",
       "      <td>-10.887386</td>\n",
       "      <td>4.345160</td>\n",
       "      <td>-11.610110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.794973</td>\n",
       "      <td>6.889330</td>\n",
       "      <td>1.424413</td>\n",
       "      <td>-0.571910</td>\n",
       "      <td>-0.550162</td>\n",
       "      <td>-1.709335</td>\n",
       "      <td>-1.310455</td>\n",
       "      <td>1.598313</td>\n",
       "      <td>1.397186</td>\n",
       "      <td>-2.306628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1          2         3          4         5          6  \\\n",
       "0 -0.258671 -2.587523   3.675304  5.038008  -6.668222 -1.726515 -13.880798   \n",
       "1  2.636475  5.572082  13.566373  6.943092 -14.104278  3.698562   5.460308   \n",
       "2 -4.794973  6.889330   1.424413 -0.571910  -0.550162 -1.709335  -1.310455   \n",
       "\n",
       "           7         8          9  \n",
       "0  11.955110  0.665868   2.337876  \n",
       "1 -10.887386  4.345160 -11.610110  \n",
       "2   1.598313  1.397186  -2.306628  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_model = 'runs:/f35718cb70f542aa8b59eca0cc7e1a70/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "loaded_model.predict(pd.DataFrame(test_input_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31T11:18:42+0900 [INFO] [cli] Prometheus metrics for HTTP BentoServer from \"service:svc\" can be accessed at http://localhost:3000/metrics.\n",
      "2022-10-31T11:18:43+0900 [INFO] [cli] Starting development HTTP BentoServer from \"service:svc\" running on http://0.0.0.0:3000 (Press CTRL+C to quit)\n",
      "2022-10-31 11:18:44 circus[2119121] [INFO] Loading the plugin...\n",
      "2022-10-31 11:18:44 circus[2119121] [INFO] Endpoint: 'tcp://127.0.0.1:36727'\n",
      "2022-10-31 11:18:44 circus[2119121] [INFO] Pub/sub: 'tcp://127.0.0.1:39683'\n",
      "2022-10-31T11:18:44+0900 [INFO] [observer] Watching directories: ['/home/khkim/aip/AIP', '/home/khkim/bentoml/models']\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve service:svc --reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "288becf193375584307ddbfdcfd61ec27209731cf4baf371ed9f89fbe55794fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
