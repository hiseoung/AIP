{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "API request to endpoint /api/2.0/mlflow/experiments/get-by-name failed with error code 403 != 200. Response body: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/gimgihun/AIP/practice.ipynb 셀 1\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimgihun/AIP/practice.ipynb#W0sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimgihun/AIP/practice.ipynb#W0sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m experiment_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmnist\u001b[39m\u001b[39m'\u001b[39m \u001b[39m# 실험명, 실험관리를 용이하게 해줍니다. \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gimgihun/AIP/practice.ipynb#W0sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mlflow\u001b[39m.\u001b[39;49mget_experiment_by_name(experiment_name): \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimgihun/AIP/practice.ipynb#W0sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m   mlflow\u001b[39m.\u001b[39mcreate_experiment(name\u001b[39m=\u001b[39mexperiment_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimgihun/AIP/practice.ipynb#W0sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m experiment \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39mget_experiment_by_name(experiment_name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/mlflow/tracking/fluent.py:1049\u001b[0m, in \u001b[0;36mget_experiment_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_experiment_by_name\u001b[39m(name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Experiment]:\n\u001b[1;32m   1020\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[39m    Retrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m        Creation timestamp: 1662004217511\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1049\u001b[0m     \u001b[39mreturn\u001b[39;00m MlflowClient()\u001b[39m.\u001b[39;49mget_experiment_by_name(name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/mlflow/tracking/client.py:585\u001b[0m, in \u001b[0;36mMlflowClient.get_experiment_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_experiment_by_name\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Experiment]:\n\u001b[1;32m    555\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39m    Retrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[39m        Lifecycle_stage: active\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mget_experiment_by_name(name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:241\u001b[0m, in \u001b[0;36mTrackingServiceClient.get_experiment_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_experiment_by_name\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[1;32m    237\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m    :param name: The experiment name.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m    :return: :py:class:`mlflow.entities.Experiment`\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mget_experiment_by_name(name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:332\u001b[0m, in \u001b[0;36mRestStore.get_experiment_by_name\u001b[0;34m(self, experiment_name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[39mreturn\u001b[39;00m experiment\n\u001b[1;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:319\u001b[0m, in \u001b[0;36mRestStore.get_experiment_by_name\u001b[0;34m(self, experiment_name)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     req_body \u001b[39m=\u001b[39m message_to_json(GetExperimentByName(experiment_name\u001b[39m=\u001b[39mexperiment_name))\n\u001b[0;32m--> 319\u001b[0m     response_proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_endpoint(GetExperimentByName, req_body)\n\u001b[1;32m    320\u001b[0m     \u001b[39mreturn\u001b[39;00m Experiment\u001b[39m.\u001b[39mfrom_proto(response_proto\u001b[39m.\u001b[39mexperiment)\n\u001b[1;32m    321\u001b[0m \u001b[39mexcept\u001b[39;00m MlflowException \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:57\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     55\u001b[0m endpoint, method \u001b[39m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m     56\u001b[0m response_proto \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mResponse()\n\u001b[0;32m---> 57\u001b[0m \u001b[39mreturn\u001b[39;00m call_endpoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_host_creds(), endpoint, method, json_body, response_proto)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:280\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     response \u001b[39m=\u001b[39m http_request(\n\u001b[1;32m    278\u001b[0m         host_creds\u001b[39m=\u001b[39mhost_creds, endpoint\u001b[39m=\u001b[39mendpoint, method\u001b[39m=\u001b[39mmethod, json\u001b[39m=\u001b[39mjson_body\n\u001b[1;32m    279\u001b[0m     )\n\u001b[0;32m--> 280\u001b[0m response \u001b[39m=\u001b[39m verify_rest_response(response, endpoint)\n\u001b[1;32m    281\u001b[0m js_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    282\u001b[0m parse_dict(js_dict\u001b[39m=\u001b[39mjs_dict, message\u001b[39m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:212\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m         base_msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAPI request to endpoint \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m failed with error code \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m != 200\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[1;32m    209\u001b[0m             endpoint,\n\u001b[1;32m    210\u001b[0m             response\u001b[39m.\u001b[39mstatus_code,\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0m         \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    213\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Response body: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (base_msg, response\u001b[39m.\u001b[39mtext),\n\u001b[1;32m    214\u001b[0m             error_code\u001b[39m=\u001b[39mget_error_code(response\u001b[39m.\u001b[39mstatus_code),\n\u001b[1;32m    215\u001b[0m         )\n\u001b[1;32m    217\u001b[0m \u001b[39m# Skip validation for endpoints (e.g. DBFS file-download API) which may return a non-JSON\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# response\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39mif\u001b[39;00m endpoint\u001b[39m.\u001b[39mstartswith(_REST_API_PATH_PREFIX) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _can_parse_as_json_object(response\u001b[39m.\u001b[39mtext):\n",
      "\u001b[0;31mMlflowException\u001b[0m: API request to endpoint /api/2.0/mlflow/experiments/get-by-name failed with error code 403 != 200. Response body: ''"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import mlflow # mlflow 사용을 위해\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784,100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100,100)\n",
    "        self.fc3 = nn.Linear(100,10)\n",
    "    def forward(self, x):\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.relu(x1)\n",
    "        x3 = self.fc2(x2)\n",
    "        x4 = self.relu(x3)\n",
    "        x5 = self.fc3(x4)\n",
    "\n",
    "        return x5\n",
    "\n",
    "download_root = 'MNIST_data/'\n",
    "\n",
    "train_dataset = datasets.MNIST(root=download_root,\n",
    "                         train=True,\n",
    "                         transform = transforms.ToTensor(),\n",
    "                         download=True)\n",
    "                         \n",
    "test_dataset = datasets.MNIST(root=download_root,\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)    \n",
    "\n",
    "batch_size = 100\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = Net()\n",
    "model.zero_grad()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.02\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "experiment_name = 'mnist' # 실험명, 실험관리를 용이하게 해줍니다. \n",
    "\n",
    "\n",
    "if not mlflow.get_experiment_by_name(experiment_name): \n",
    "  mlflow.create_experiment(name=experiment_name)\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "#mlflow.set_tag(\"mlflow.runName\",\"practice\")\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(seed)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "total_batch = len(train_loader)\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "best_accuracy = 0\n",
    "with mlflow.start_run(experiment_id=experiment.experiment_id,run_name=\"autoever\"):\n",
    "  for epoch in range(epochs):\n",
    "      cost=0\n",
    "      model.train()\n",
    "      train_accuracy = 0\n",
    "      train_loss = 0\n",
    "      for images, labels in train_loader:\n",
    "          images = images.reshape(100,784)\n",
    "          \n",
    "          optimizer.zero_grad() # 변화도 매개변수 0\n",
    "          \n",
    "          #forward\n",
    "          #pred = model.forward(images)\n",
    "          #loss = loss_function(pred, labels)\n",
    "          pred = model(images)\n",
    "          loss = loss_function(pred,labels)\n",
    "          prediction = torch.argmax(pred,1)\n",
    "          correct = (prediction == labels)\n",
    "          train_accuracy += correct.sum().item() / 60000\n",
    "          train_loss += loss.item() / 600\n",
    "          \n",
    "          #backward\n",
    "          loss.backward()\n",
    "          \n",
    "          #Update\n",
    "          optimizer.step()\n",
    "          \n",
    "          cost += loss\n",
    "      \n",
    "      with torch.no_grad(): #미분하지 않겠다는 것\n",
    "          total = 0\n",
    "          correct=0\n",
    "          for images, labels in test_loader:\n",
    "              images = images.reshape(100,784)\n",
    "\n",
    "              outputs = model(images)\n",
    "              _,predict = torch.max(outputs.data, 1)\n",
    "\n",
    "              total += labels.size(0)\n",
    "              correct += (predict==labels).sum() # 예측한 값과 일치한 값의 합\n",
    "\n",
    "      avg_cost = cost / total_batch\n",
    "      accuracy = 100*correct/total\n",
    "      \n",
    "      val_loss_list.append(avg_cost.detach().numpy())\n",
    "      val_acc_list.append(accuracy)\n",
    "\n",
    "      if accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(),'model.pt')\n",
    "        best_accuracy = accuracy\n",
    "        print(f\"Save Model(Epoch: {epoch+1}, Accuracy: {best_accuracy:.5})\")\n",
    "      \n",
    "      print(\"epoch : {} | loss : {:.6f}\" .format(epoch+1, avg_cost))\n",
    "      print(\"Accuracy : {:.2f}\".format(100*correct/total))\n",
    "      mlflow.log_param('learning-rate',learning_rate) # mlflow.log_param 을 사용하여 MLflow에 파라미터들을 기록할 수 있습니다.\n",
    "      mlflow.log_param('epoch',epochs)\n",
    "      mlflow.log_param('batch_size',batch_size)\n",
    "      mlflow.log_param('seed',seed)\n",
    "      mlflow.log_metric('train_accuracy',train_accuracy) # mlflow.log_metric을 사용하여 MLflow에 성능평가를 위한 metric을 기록할 수 있습니다.\n",
    "      mlflow.log_metric('train_loss',train_loss)\n",
    "      mlflow.log_metric('valid_accuracy',accuracy)\n",
    "      mlflow.log_metric('valid_loss',avg_cost)\n",
    "      mlflow.pytorch.log_model(model,'model') # pytorch.log_model 을 통해 모델을 저장할 수 있습니다.\n",
    "      print(\"------\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bentoml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(tag=\"torch_mmnist_model:fco4nxswpsh6f2kn\", path=\"/home/khkim/bentoml/models/torch_mmnist_model/fco4nxswpsh6f2kn/\")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mlflow 모델 저장\n",
    "mlflow.pytorch.save_model(model, './model_mlflow')\n",
    "\n",
    "# bentoml model import\n",
    "bentoml.mlflow.import_model(\"torch_mmnist_model\", model_uri='./model_mlflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.pytorch.log_model(model, artifact_path=\"pytorch-model\")\n",
    "\n",
    "    model_uri = mlflow.get_artifact_uri(\"pytorch-model\")\n",
    "    bento_model = bentoml.mlflow.import_model(\n",
    "        'mlflow_pytorch_mnist',\n",
    "        model_uri,\n",
    "        signatures={'predict': {'batchable': True}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[0m\u001b[1mTag                          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mModule        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\n",
      " mlflow_pytorch_mnist:fwakrmc…  bentoml.mlflow  355.50 KiB  2022-10-28 13:51:25 \n",
      " mlflow_pytorch_mnist:5wff3nc…  bentoml.mlflow  355.50 KiB  2022-10-28 13:13:50 \n",
      " mlflow_pytorch_mnist:aninu4s…  bentoml.mlflow  355.50 KiB  2022-10-28 11:05:36 \n"
     ]
    }
   ],
   "source": [
    "!bentoml models list mlflow_pytorch_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test_input_arr.json', 'r') as f:\n",
    "  test_input_arr = np.array(json.load(f), dtype=np.float32)\n",
    "input_df = pd.DataFrame(test_input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bento_model = bentoml.mlflow.get(\"mlflow_pytorch_mnist:latest\")\n",
    "mlflow_model_path = bento_model.path_of(bentoml.mlflow.MLFLOW_MODEL_FOLDER)\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "loaded_pytorch_model = mlflow.pytorch.load_model(mlflow_model_path)\n",
    "loaded_pytorch_model.to(device)\n",
    "loaded_pytorch_model.eval()\n",
    "with torch.no_grad():\n",
    "    input_tensor = torch.from_numpy(test_input_arr).to(device)\n",
    "    predictions = loaded_pytorch_model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyfunc_model: mlflow.pyfunc.PyFuncModel = bentoml.mlflow.load_model(\"mlflow_pytorch_mnist:latest\")\n",
    "predictions = pyfunc_model.predict(test_input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Runner.init_local' is for debugging and testing only.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.380183</td>\n",
       "      <td>-6.570198</td>\n",
       "      <td>3.705701</td>\n",
       "      <td>5.251037</td>\n",
       "      <td>-6.438535</td>\n",
       "      <td>0.700532</td>\n",
       "      <td>-10.802313</td>\n",
       "      <td>10.078778</td>\n",
       "      <td>-0.238268</td>\n",
       "      <td>2.461140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.148345</td>\n",
       "      <td>-0.520767</td>\n",
       "      <td>10.006227</td>\n",
       "      <td>5.027098</td>\n",
       "      <td>-10.536626</td>\n",
       "      <td>4.742851</td>\n",
       "      <td>4.861799</td>\n",
       "      <td>-10.102612</td>\n",
       "      <td>3.077540</td>\n",
       "      <td>-9.618299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.207930</td>\n",
       "      <td>6.709457</td>\n",
       "      <td>1.573217</td>\n",
       "      <td>0.601503</td>\n",
       "      <td>-1.886631</td>\n",
       "      <td>-0.769723</td>\n",
       "      <td>-0.192309</td>\n",
       "      <td>1.179303</td>\n",
       "      <td>0.823319</td>\n",
       "      <td>-2.092222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1          2         3          4         5          6  \\\n",
       "0  1.380183 -6.570198   3.705701  5.251037  -6.438535  0.700532 -10.802313   \n",
       "1  3.148345 -0.520767  10.006227  5.027098 -10.536626  4.742851   4.861799   \n",
       "2 -5.207930  6.709457   1.573217  0.601503  -1.886631 -0.769723  -0.192309   \n",
       "\n",
       "           7         8         9  \n",
       "0  10.078778 -0.238268  2.461140  \n",
       "1 -10.102612  3.077540 -9.618299  \n",
       "2   1.179303  0.823319 -2.092222  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner = bentoml.mlflow.get(\"mlflow_pytorch_mnist:latest\").to_runner()\n",
    "runner.init_local()\n",
    "runner.predict.run(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-28T13:51:53+0900 [INFO] [cli] Prometheus metrics for HTTP BentoServer from \"service:svc\" can be accessed at http://localhost:3000/metrics.\n",
      "2022-10-28T13:51:53+0900 [INFO] [cli] Starting development HTTP BentoServer from \"service:svc\" running on http://0.0.0.0:3000 (Press CTRL+C to quit)\n",
      "2022-10-28 13:51:54 circus[2687206] [INFO] Loading the plugin...\n",
      "2022-10-28 13:51:54 circus[2687206] [INFO] Endpoint: 'tcp://127.0.0.1:54021'\n",
      "2022-10-28 13:51:54 circus[2687206] [INFO] Pub/sub: 'tcp://127.0.0.1:58045'\n",
      "2022-10-28T13:51:54+0900 [INFO] [observer] Watching directories: ['/home/khkim/aip/AIP', '/home/khkim/bentoml/models']\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve service:svc --reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
